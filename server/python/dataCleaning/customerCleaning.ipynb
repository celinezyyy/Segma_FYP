{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d01967",
   "metadata": {},
   "source": [
    "## Customer Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30abd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (0.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (25.2)\n",
      "Requirement already satisfied: python-Levenshtein in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: Levenshtein==0.27.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from python-Levenshtein) (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (2.3.3)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting jupyter\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: notebook in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter) (7.4.7)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: nbconvert in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter) (7.0.0)\n",
      "Collecting ipywidgets (from jupyter)\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: jupyterlab in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter) (4.4.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (9.6.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.5.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (311)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipywidgets->jupyter) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from ipywidgets->jupyter) (3.0.15)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab->jupyter) (80.9.0)\n",
      "Requirement already satisfied: anyio in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.23.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.25.1)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab->jupyter) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.27.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from nbconvert->jupyter) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from nbconvert->jupyter) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20251008)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\y3s2\\fyp\\venv_fyp_new\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: contourpy, scikit-learn, matplotlib, seaborn, ipywidgets, jupyter-console, jupyter\n",
      "\n",
      "   ---------------------------------------- 0/7 [contourpy]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----- ---------------------------------- 1/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------- ---------------------------- 2/7 [matplotlib]\n",
      "   ----------------- ---------------------- 3/7 [seaborn]\n",
      "   ----------------- ---------------------- 3/7 [seaborn]\n",
      "   ----------------- ---------------------- 3/7 [seaborn]\n",
      "   ----------------- ---------------------- 3/7 [seaborn]\n",
      "   ----------------- ---------------------- 3/7 [seaborn]\n",
      "   ----------------- ---------------------- 3/7 [seaborn]\n",
      "   ----------------- ---------------------- 3/7 [seaborn]\n",
      "   ---------------------- ----------------- 4/7 [ipywidgets]\n",
      "   ---------------------- ----------------- 4/7 [ipywidgets]\n",
      "   ---------------------- ----------------- 4/7 [ipywidgets]\n",
      "   ---------------------- ----------------- 4/7 [ipywidgets]\n",
      "   ---------------------- ----------------- 4/7 [ipywidgets]\n",
      "   ---------------------- ----------------- 4/7 [ipywidgets]\n",
      "   ---------------------------- ----------- 5/7 [jupyter-console]\n",
      "   ---------------------------- ----------- 5/7 [jupyter-console]\n",
      "   ---------------------------------------- 7/7 [jupyter]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 ipywidgets-8.1.7 jupyter-1.1.1 jupyter-console-6.6.3 matplotlib-3.10.7 scikit-learn-1.7.2 seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fuzzywuzzy\n",
    "!python -m pip install --upgrade pip\n",
    "%pip install python-Levenshtein\n",
    "%pip install pandas numpy matplotlib seaborn scikit-learn jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate kernal:\n",
    "# .\\venv_fyp\\Scripts\\activate\n",
    "\n",
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, date\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import pycountry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4769ad2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income Level</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sungai Besi</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "      <td>Malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUST0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUST0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mutiara Damansara</td>\n",
       "      <td>Selangor</td>\n",
       "      <td>Malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUST0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shah Alam</td>\n",
       "      <td>Selangor</td>\n",
       "      <td>Malaysia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CustomerID  Date of Birth  Gender  Income Level               City  \\\n",
       "0   CUST0001            NaN  female           NaN        Sungai Besi   \n",
       "1   CUST0001            NaN  female           NaN                NaN   \n",
       "2   CUST0002            NaN  female           NaN  Mutiara Damansara   \n",
       "3   CUST0002            NaN  female           NaN                NaN   \n",
       "4   CUST0003            NaN  female           NaN          Shah Alam   \n",
       "\n",
       "          State   Country  \n",
       "0  Kuala Lumpur  Malaysia  \n",
       "1           NaN       NaN  \n",
       "2      Selangor  Malaysia  \n",
       "3           NaN       NaN  \n",
       "4      Selangor  Malaysia  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load dataset\n",
    "# Replace 'customer_dataset.csv' with your actual file name or path\n",
    "file_path = \"C:/Users/user/OneDrive/Desktop/Onedrive_YuyanDipsy/OneDrive/UM Y4S1/WIA3002 FYP 1 & 2/FYP2/Data/Soapan Santun/2021 - 2025 Customer.csv\"\n",
    "\n",
    "original_dataset_name = \"2021 - 2025 Customer.csv\"\n",
    "\n",
    "# Read dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe554a9",
   "metadata": {},
   "source": [
    "### Data Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd905e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706371d9",
   "metadata": {},
   "source": [
    "### Initial checking: (Before perform data cleaning) Check optional and mandatory columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508463d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional columns\n",
    "def check_optional_columns(df, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Check optional columns for fill percentage and drop columns that are mostly empty.\n",
    "    Returns the modified DataFrame and a friendly message.\n",
    "    \"\"\"\n",
    "    \n",
    "    optional_columns = [\"Date of Birth\", \"Gender\", \"Income Level\"]\n",
    "\n",
    "    # Normalize column names\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    optional_columns = [col.lower() for col in optional_columns]\n",
    "\n",
    "    dropped_columns = []\n",
    "\n",
    "    for col in optional_columns:\n",
    "        if col in df.columns:\n",
    "            fill_ratio = df[col].count() / len(df) # \n",
    "            if fill_ratio < threshold:\n",
    "                dropped_columns.append(col)\n",
    "                df.drop(columns=[col], inplace=True)  # Drop the column immediately\n",
    "                # df[col].count(): This counts the number of non-missing (non-null/non-NaN) values in the current column (col).\n",
    "                # len(df): This gives the total number of rows in the DataFrame.\n",
    "                # fill_ratio: The division calculates the proportion of filled (non-missing) values in that column. A ratio of 1.0 means the column is entirely filled; a ratio of 0.1 means 90% of the values are missing.\n",
    "\n",
    "\n",
    "    # Generate user-friendly message\n",
    "    if dropped_columns:\n",
    "        dropped_str = \", \".join(dropped_columns)\n",
    "        message = (\n",
    "            f\"We noticed that very few entries were provided for {dropped_str}. \"\n",
    "            \"These columns have been removed. \"\n",
    "            \"Segmentation will still be performed using geographic (City, State, Country) \"\n",
    "            \"and behavioral data (e.g., orders, purchase items, total spend).\"\n",
    "        )\n",
    "    else:\n",
    "        message = \"All optional columns have enough data and are kept for analysis.\"\n",
    "    \n",
    "    return df, message\n",
    "\n",
    "# Mandatory columns \n",
    "def check_mandatory_columns(df, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Check mandatory columns for missing values (column-wise).\n",
    "    Does not drop columns — only warns user if any column is too incomplete.\n",
    "    Returns the DataFrame and a message summarizing issues.\n",
    "    \"\"\"\n",
    "\n",
    "    mandatory_columns = [\"CustomerID\", \"City\", \"State\", \"Country\"]\n",
    "\n",
    "    # Normalize column names\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    mandatory_columns = [col.lower() for col in mandatory_columns]\n",
    "\n",
    "    missing_report = []\n",
    "    warning_columns = []\n",
    "\n",
    "    for col in mandatory_columns:\n",
    "        if col in df.columns:\n",
    "            fill_ratio = df[col].count() / len(df)\n",
    "            missing_percent = (1 - fill_ratio) * 100\n",
    "\n",
    "            missing_report.append(f\"{col}: {missing_percent:.1f}% missing\")\n",
    "\n",
    "            # Warn if missing exceeds threshold\n",
    "            if fill_ratio < (1 - threshold):\n",
    "                warning_columns.append(col)\n",
    "        else:\n",
    "            # Handle case where column completely missing\n",
    "            missing_report.append(f\"{col}: column not found (100% missing)\")\n",
    "            warning_columns.append(col)\n",
    "\n",
    "    # Generate friendly message\n",
    "    if warning_columns:\n",
    "        warning_str = \", \".join(warning_columns)\n",
    "        message = (\n",
    "            f\"Some key fields have a high number of missing values: {warning_str}. \"\n",
    "            \"The system will still continue cleaning and processing, \"\n",
    "            \"but missing values will be handled automatically by our system. \"\n",
    "            \"Please ensure your source data is as complete as possible for more accurate segmentation results.\\n\\n\"\n",
    "            \"Missing Data Summary:\\n\" + \"\\n\".join(missing_report)\n",
    "        )\n",
    "    else:\n",
    "        message = (\n",
    "            \"All mandatory columns have sufficient data and are ready for cleaning.\\n\\n\"\n",
    "            \"Missing Data Summary:\\n\" + \"\\n\".join(missing_report)\n",
    "        )\n",
    "\n",
    "    return df, message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea956f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optional Columns Check:\n",
      "We noticed that very few entries were provided for date of birth, income level. These columns have been removed. Segmentation will still be performed using geographic (City, State, Country) and behavioral data (e.g., orders, purchase items, total spend).\n",
      "\n",
      "Mandatory Columns Check:\n",
      "Some key fields have a high number of missing values: city, state, country. The system will still continue cleaning and processing, but missing values will be handled automatically by our system. Please ensure your source data is as complete as possible for more accurate segmentation results.\n",
      "\n",
      "Missing Data Summary:\n",
      "customerid: 0.0% missing\n",
      "city: 44.8% missing\n",
      "state: 46.9% missing\n",
      "country: 44.7% missing\n",
      "\n",
      "Cleaned dataset saved as '2021 - 2025 Customer_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# --- Apply checks and save cleaned dataset ---\n",
    "# Step 1: Optional columns\n",
    "df, optional_check_message = check_optional_columns(df)\n",
    "\n",
    "# Step 2: Mandatory columns (just check, but keep all columns)\n",
    "df, mandatory_check_message = check_mandatory_columns(df)\n",
    "\n",
    "# Step 3: Save the updated dataset for cleaning\n",
    "\n",
    "# Split the name and extension\n",
    "base_name, ext = os.path.splitext(original_dataset_name)\n",
    "\n",
    "# Create new cleaned file name\n",
    "cleaned_file = f\"{base_name}_cleaned{ext}\"\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv(cleaned_file, index=False)\n",
    "\n",
    "# --- Display results ---\n",
    "print(\"Optional Columns Check:\")\n",
    "print(optional_check_message)\n",
    "\n",
    "print(\"\\nMandatory Columns Check:\")\n",
    "print(mandatory_check_message)\n",
    "\n",
    "print(f\"\\nCleaned dataset saved as '{cleaned_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354c5c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST0001</td>\n",
       "      <td>female</td>\n",
       "      <td>Sungai Besi</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "      <td>Malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUST0001</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUST0002</td>\n",
       "      <td>female</td>\n",
       "      <td>Mutiara Damansara</td>\n",
       "      <td>Selangor</td>\n",
       "      <td>Malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUST0002</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST0003</td>\n",
       "      <td>female</td>\n",
       "      <td>Shah Alam</td>\n",
       "      <td>Selangor</td>\n",
       "      <td>Malaysia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customerid  gender               city         state   country\n",
       "0   CUST0001  female        Sungai Besi  Kuala Lumpur  Malaysia\n",
       "1   CUST0001  female                NaN           NaN       NaN\n",
       "2   CUST0002  female  Mutiara Damansara      Selangor  Malaysia\n",
       "3   CUST0002  female                NaN           NaN       NaN\n",
       "4   CUST0003  female          Shah Alam      Selangor  Malaysia"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After perform initial checking on optional and mandatory columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f407f8",
   "metadata": {},
   "source": [
    "### Perform Data Cleaning - CustomerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================= STAGE 3: STANDARDIZATION & NORMALIZATION =============================================\n",
    "\n",
    "def normalize_columns_name(df):\n",
    "    \"\"\"Normalize column names: lowercase, strip spaces\"\"\"\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    return df\n",
    "\n",
    "# ===============================================================================\n",
    "\n",
    "def standardize_customer_id(df):\n",
    "    \"\"\"Standardize CustomerID format\"\"\"\n",
    "    if 'customerid' in df.columns:\n",
    "        df['customerid'] = df['customerid'].astype(str).str.strip().str.upper()\n",
    "    return df\n",
    "\n",
    "# ===============================================================================\n",
    "\n",
    "def standardize_dob(df):\n",
    "    \"\"\"Standardize Date of Birth column and convert to YYYY-MM-DD\"\"\"\n",
    "    if 'dob' in df.columns:\n",
    "        def parse_date(x):\n",
    "            if pd.isnull(x):\n",
    "                return np.nan\n",
    "            for format in (\"%d/%m/%Y\", \"%m-%d-%y\", \"%Y-%m-%d\", \"%d-%b-%Y\", \"%d-%m-%Y\"):    \n",
    "                try:\n",
    "                    return datetime.strptime(str(x), format).date() # Final format: YYYY-MM-DD | 2025-10-15\n",
    "                except Exception:\n",
    "                    continue\n",
    "            return np.nan  # If no valid format found\n",
    "        df['dob'] = df['dob'].apply(parse_date)\n",
    "    return df\n",
    "\n",
    "# %d/%m/%Y → 12/05/2000\n",
    "# %m-%d-%y → 05-12-00\n",
    "# %Y-%m-%d → 2000-05-12\n",
    "# %d-%b-%Y → 12-May-2000\n",
    "# %d-%m-%Y → 12-5-2000\n",
    "\n",
    "# ===============================================================================\n",
    "\n",
    "def derive_age_features(df):\n",
    "    \"\"\"Derive Age from DOB\"\"\"\n",
    "    if 'dob' in df.columns:\n",
    "        today = date.today()\n",
    "        df['age'] = df['dob'].apply(\n",
    "            lambda x: today.year - x.year - ((today.month, today.day) < (x.month, x.day))\n",
    "            if pd.notnull(x) else np.nan\n",
    "        )\n",
    "    return df\n",
    "# Example: ((today.month, today.day) < (x.month, x.day))\n",
    "# (10,15) < (12,1) → True (birthday in Dec is after Oct 15)\n",
    "# (10,15) < (10,16) → True (birthday tomorrow)\n",
    "# (10,15) < (5,20) → False (birthday already passed)\n",
    "\n",
    "# This function calculates each person’s age from their date of birth (dob) by subtracting their birth year from the current year and adjusting if their birthday hasn’t occurred yet this year.\n",
    "\n",
    "# ===============================================================================\n",
    "\n",
    "def derive_age_group(df):\n",
    "    \"\"\"Derive Age Group based on defined buckets\"\"\"\n",
    "    if 'age' in df.columns:\n",
    "        def categorize_age(age):\n",
    "            if pd.isnull(age):\n",
    "                return 'Unknown'\n",
    "            if age < 18: return 'Below 18'\n",
    "            elif 18 <= age <= 24: return '18-24'\n",
    "            elif 25 <= age <= 34: return '25-34'\n",
    "            elif 35 <= age <= 44: return '35-44'\n",
    "            elif 45 <= age <= 54: return '45-54'\n",
    "            elif 55 <= age <= 64: return '55-64'\n",
    "            else: return 'Above 65'\n",
    "        df['age_group'] = df['age'].apply(categorize_age)\n",
    "    return df\n",
    "\n",
    "# =================================================================================\n",
    "\n",
    "def standardize_gender(df):\n",
    "    \"\"\"Clean and standardize gender values\"\"\"\n",
    "    if 'gender' in df.columns:\n",
    "        # Clean text (remove spaces, make lowercase)\n",
    "        df['gender'] = df['gender'].astype(str).str.strip().str.lower()\n",
    "\n",
    "        # Standardize using keyword detection\n",
    "        def detect_gender(value):\n",
    "            if any(word in value for word in ['m', 'male', 'man', 'boy']):\n",
    "                return 'Male'\n",
    "            elif any(word in value for word in ['f', 'female', 'woman', 'girl']):\n",
    "                return 'Female'\n",
    "            else:\n",
    "                return 'Unknown'\n",
    "\n",
    "        df['gender'] = df['gender'].apply(detect_gender)\n",
    "    return df\n",
    "\n",
    "# ==================================================================================\n",
    "\n",
    "def standardize_location(df):\n",
    "    \"\"\"Standardize City, State, Country using fuzzy and pycountry\"\"\"\n",
    "    #  City \n",
    "    if 'city' in df.columns:\n",
    "        df['city'] = df['city'].astype(str).str.title().str.strip()\n",
    "\n",
    "    # State \n",
    "    if 'state' in df.columns:\n",
    "        states = [sub.name for sub in pycountry.subdivisions if sub.country_code == 'MY']\n",
    "        df['state'] = df['state'].astype(str).str.title().str.strip()\n",
    "        df['state'] = df['state'].apply(\n",
    "            lambda x: process.extractOne(x, states, scorer=fuzz.token_sort_ratio)[0] if x else 'Unknown'\n",
    "        )\n",
    "\n",
    "    # Country ---\n",
    "    if 'country' in df.columns:\n",
    "        countries = [c.name for c in pycountry.countries]\n",
    "        df['country'] = df['country'].astype(str).str.title().str.strip()\n",
    "        df['country'] = df['country'].apply(\n",
    "            lambda x: process.extractOne(x, countries, scorer=fuzz.token_sort_ratio)[0]\n",
    "            if x and len(x) > 2 else 'Malaysia'\n",
    "        )\n",
    "    return df\n",
    "\n",
    "# =============================================(WIP) STAGE 4: MISSING VALUE HANDLING =============================================\n",
    "\n",
    "def handle_missing_values_row_aware(df, min_cols_filled=2, city_to_state=None):\n",
    "    \"\"\"\n",
    "    Handle missing values in a row-aware way.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - min_cols_filled: minimum number of non-null columns to keep row\n",
    "    - city_to_state: optional dict to map city -> state for row-based imputation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop rows with too few columns filled\n",
    "    df = df[df.notna().sum(axis=1) >= min_cols_filled]\n",
    "\n",
    "    # Handle customerid\n",
    "    if 'customerid' in df.columns:\n",
    "        df = df[df['customerid'].notna()]  # cannot keep rows without ID\n",
    "\n",
    "    # Handle Age (Can use ML prediction later)\n",
    "    if 'age' in df.columns:\n",
    "        median_age = df['age'].median()\n",
    "        df['age'] = df['age'].fillna(median_age)\n",
    "\n",
    "    # Step 4: Handle Gender\n",
    "    if 'gender' in df.columns:\n",
    "        missing_ratio = df['gender'].isna().mean()\n",
    "        if missing_ratio > 0.5:\n",
    "            df['gender'] = df['gender'].fillna('Unknown')\n",
    "        else:\n",
    "            df['gender'] = df['gender'].fillna(df['gender'].mode()[0])\n",
    "\n",
    "    # Step 5: Handle City, State, Country\n",
    "    for col in ['city', 'state', 'country']:\n",
    "        if col in df.columns:\n",
    "            if col == 'country':\n",
    "                df[col] = df[col].fillna('Malaysia')\n",
    "            elif col == 'state':\n",
    "                # fill based on city mapping if provided\n",
    "                if city_to_state:\n",
    "                    df['state'] = df.apply(\n",
    "                        lambda r: city_to_state.get(r['city'], r['state']) \n",
    "                        if pd.isna(r['state']) else r['state'], axis=1\n",
    "                    )\n",
    "                # fallback to mode\n",
    "                df['state'] = df['state'].fillna(df['state'].mode()[0])\n",
    "            else:  # city\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    # -------------------\n",
    "    # Optional Step 6: Predictive Imputation (Placeholder)\n",
    "    # -------------------\n",
    "    # Here you could add ML-based prediction for age, gender, etc.\n",
    "    # Example:\n",
    "    # df['age'] = predictive_age_fill(df)\n",
    "    # df['gender'] = predictive_gender_fill(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "# =============================================(WIP) STAGE 5: OUTLIER DETECTION =============================================\n",
    "\n",
    "def detect_outliers(df):\n",
    "    \"\"\"Detect outliers in DOB and Age\"\"\"\n",
    "    if 'dob' in df.columns:\n",
    "        df['dob'] = df['dob'].apply(\n",
    "            lambda x: np.nan if pd.notnull(x) and (date.today().year - x.year > 110 or date.today().year - x.year < 0) else x\n",
    "        )\n",
    "\n",
    "    if 'age' in df.columns:\n",
    "        df['age'] = df['age'].apply(lambda x: np.nan if pd.notnull(x) and (x < 0 or x > 110) else x)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================= STAGE 6: DEDUPLICATION =============================================\n",
    "# This function removes duplicate CustomerIDs and keeps the row with the most non-missing data to preserve the most complete customer record.\n",
    "def deduplicate_customers(df):\n",
    "    \"\"\"Keep the most complete record for each CustomerID\"\"\"\n",
    "    if 'customerid' in df.columns:\n",
    "        df = (\n",
    "            df.loc[df.groupby('customerid').apply(lambda x: x.notna().sum(axis=1).idxmax())]\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "# =============== MAIN PIPELINE ===============\n",
    "\n",
    "def clean_customer_dataset(df):\n",
    "    df = normalize_columns_name(df)\n",
    "    df = standardize_customer_id(df)\n",
    "    df = standardize_dob(df)\n",
    "    df = derive_age_features(df)\n",
    "    df = derive_age_group(df)\n",
    "\n",
    "    df = standardize_gender(df)\n",
    "    df = standardize_location(df)\n",
    "\n",
    "    df = handle_missing_values_row_aware(df)\n",
    "    df = detect_outliers(df)\n",
    "    df = deduplicate_customers(df)\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP Kernel",
   "language": "python",
   "name": "fyp_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
